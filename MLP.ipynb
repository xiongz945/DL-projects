{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1P2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w9IRpXpdad7"
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyX7Kqc1ia-D"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "X = np.load(\"/content/train.npy\", allow_pickle=True)\n",
        "Y = np.load(\"/content/train_labels.npy\", allow_pickle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSWR1FaApOm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7d999ec0-8515-4b9f-cb19-20da8fc78a98"
      },
      "source": [
        "for x in X:\n",
        "  total_datapoints += x.shape[0]\n",
        "print(total_datapoints)\n",
        "print(X[0].shape)\n",
        "print(Y[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27329537\n",
            "(1406, 13)\n",
            "(1406,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHC93O2YxpEY"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "CONTEXT_SIZE = 24\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    super(MyDataset, self).__init__()\n",
        "    self.X = []\n",
        "    self.map = [0] * total_datapoints\n",
        "    current_lower = 0\n",
        "    convert_Y = np.array([])\n",
        "    for index, utterance in np.ndenumerate(X):\n",
        "      size = utterance.shape[0]\n",
        "      padded_utterance = np.pad(utterance,((CONTEXT_SIZE,), (0,)), 'constant')\n",
        "      self.X.append(padded_utterance)\n",
        "      self.map[current_lower:current_lower+size] = [(index[0], k+CONTEXT_SIZE) for k in range(size)]\n",
        "      current_lower += size\n",
        "      convert_Y = np.concatenate((convert_Y, Y[index]))\n",
        "\n",
        "    print(\"X length is \", len(self.X))\n",
        "    self.Y = torch.from_numpy(convert_Y)\n",
        "    print(\"Y shape is \", self.Y.size())\n",
        "      \n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return list(self.Y.size())[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    utter_idx, frame_idx = self.map[index]\n",
        "    utter = self.X[utter_idx]       \n",
        "    X = torch.from_numpy(utter[frame_idx-CONTEXT_SIZE:frame_idx+CONTEXT_SIZE+1].flatten())\n",
        "    X = X.type(torch.FloatTensor)\n",
        "    Y = self.Y[index]\n",
        "    Y = Y.type(torch.LongTensor)\n",
        "    return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XyWPwYDyi28"
      },
      "source": [
        "def xavier_init(params):\n",
        "  for m in params:\n",
        "    if isinstance(m, nn.Linear):\n",
        "      nn.init.xavier_normal_(m.weight)\n",
        "      nn.init.zeros_(m.bias)\n",
        "\n",
        "def zero_init(params):\n",
        "  for m in params:\n",
        "    if isinstance(m, nn.Linear):\n",
        "      nn.init.zeros_(m.weight)\n",
        "      nn.init.zeros_(m.bias)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear((2*CONTEXT_SIZE+1)*13,2048),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(2048),\n",
        "        nn.Linear(2048,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Linear(1024,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Linear(1024,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Linear(1024,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Linear(1024,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Linear(1024,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Linear(1024,512),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.Linear(512,346)\n",
        "    )\n",
        "  \n",
        "  def init_weights(self):\n",
        "    with torch.no_grad():\n",
        "      xavier_init(self.modules())\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layers(x)\n",
        "    \n",
        "    return out\n",
        "\n",
        "  def save(self, ckpt_path):\n",
        "    ckpt = {\n",
        "        'params': self.state_dict()\n",
        "    }\n",
        "    torch.save(ckpt, ckpt_path)\n",
        "  \n",
        "  def load(self, ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path)\n",
        "    self.load_state_dict(ckpt['params'], strict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU81eaNYyzGr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "884f0ae9-938e-444d-e5ee-c8285813d9a2"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "num_of_workers = 0 if cuda else 0\n",
        "print(\"Init started\")\n",
        "train_dataset = MyDataset(X, Y)\n",
        "del X\n",
        "del Y\n",
        "print(\"Init completed\")\n",
        "train_loader_args = dict(shuffle=True, batch_size=2048, num_workers=num_of_workers, pin_memory=True, drop_last=True) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=64)\n",
        "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
        "\n",
        "model = MyModel()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init started\n",
            "X length is  22002\n",
            "Y shape is  torch.Size([27329537])\n",
            "Init completed\n",
            "cuda\n",
            "MyModel(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=663, out_features=2048, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (16): ReLU()\n",
            "    (17): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (19): ReLU()\n",
            "    (20): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (21): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (22): ReLU()\n",
            "    (23): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (25): ReLU()\n",
            "    (26): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (28): ReLU()\n",
            "    (29): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (30): Linear(in_features=512, out_features=346, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FL22LfznjS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba98aa69-d203-4ed7-adb7-f9b219bb25ae"
      },
      "source": [
        "print(len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27329537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf3hmOKHuldv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "202ce818-05ba-45c6-f290-cea4fe6d915c"
      },
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "NUM_EPOCHS = 8\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma=0.1)\n",
        "class AvgMeter():\n",
        "    def __init__(self):\n",
        "        self.qty = 0\n",
        "        self.cnt = 0\n",
        "    \n",
        "    def update(self, increment, count):\n",
        "        self.qty += increment\n",
        "        self.cnt += count\n",
        "    \n",
        "    def get_avg(self):\n",
        "        if self.cnt == 0:\n",
        "            return 0\n",
        "        else: \n",
        "            return self.qty/self.cnt\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model.train()\n",
        "  loss_meter = AvgMeter()\n",
        "  accu_meter = AvgMeter()\n",
        "  running_loss = 0.0\n",
        "  start_time = time.time()\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    running_loss += loss.item()\n",
        "    loss_meter.update(loss.item(), 1)\n",
        "    accu_meter.update((predicted == y).sum().item(), y.size(0))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 2000 == 1999:\n",
        "      print(f\"{epoch+1} epoch, {i+1} batch, loss: {running_loss/2000}\")\n",
        "      end_time = time.time()\n",
        "      print(f\"2000 batches take {end_time-start_time} seconds\")\n",
        "      running_loss = 0.0\n",
        "      start_time = time.time()\n",
        "  \n",
        "  scheduler.step()  \n",
        "  loss = loss_meter.get_avg()\n",
        "  accu = accu_meter.get_avg()\n",
        "  print(f\"The loss is {loss} and the accuracy is {accu} in Epoch {epoch+1}\")\n",
        "\n",
        "print('Finished Training')\n",
        "model.save(\"/content/ckpt.pth\")\n",
        "torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 epoch, 2000 batch, loss: 1.5257254166007042\n",
            "2000 batches take 209.87855529785156 seconds\n",
            "1 epoch, 4000 batch, loss: 1.1565340431928635\n",
            "2000 batches take 205.4843692779541 seconds\n",
            "1 epoch, 6000 batch, loss: 1.043668802201748\n",
            "2000 batches take 205.5911991596222 seconds\n",
            "1 epoch, 8000 batch, loss: 0.9748268194794655\n",
            "2000 batches take 204.3959767818451 seconds\n",
            "1 epoch, 10000 batch, loss: 0.9282104606330395\n",
            "2000 batches take 204.53612279891968 seconds\n",
            "1 epoch, 12000 batch, loss: 0.8930591180622578\n",
            "2000 batches take 203.64968061447144 seconds\n",
            "The loss is 1.0648294854909182 and the accuracy is 0.680469869709701 in Epoch 1\n",
            "2 epoch, 2000 batch, loss: 0.8366633911132813\n",
            "2000 batches take 206.5890371799469 seconds\n",
            "2 epoch, 4000 batch, loss: 0.8204503124356269\n",
            "2000 batches take 203.66243314743042 seconds\n",
            "2 epoch, 6000 batch, loss: 0.8068840204775334\n",
            "2000 batches take 204.01112246513367 seconds\n",
            "2 epoch, 8000 batch, loss: 0.7933611751496792\n",
            "2000 batches take 204.70449876785278 seconds\n",
            "2 epoch, 10000 batch, loss: 0.7830575058162212\n",
            "2000 batches take 204.03174710273743 seconds\n",
            "2 epoch, 12000 batch, loss: 0.7708808532059193\n",
            "2000 batches take 204.08138275146484 seconds\n",
            "The loss is 0.7978214115279613 and the accuracy is 0.7533190976515662 in Epoch 2\n",
            "3 epoch, 2000 batch, loss: 0.6322004494965077\n",
            "2000 batches take 208.68457126617432 seconds\n",
            "3 epoch, 4000 batch, loss: 0.5965921021997929\n",
            "2000 batches take 204.33796906471252 seconds\n",
            "3 epoch, 6000 batch, loss: 0.5813153969794512\n",
            "2000 batches take 204.56503772735596 seconds\n",
            "3 epoch, 8000 batch, loss: 0.5708598713576793\n",
            "2000 batches take 204.43971228599548 seconds\n",
            "3 epoch, 10000 batch, loss: 0.5613680725693703\n",
            "2000 batches take 206.6099066734314 seconds\n",
            "3 epoch, 12000 batch, loss: 0.5533889725059271\n",
            "2000 batches take 206.7460961341858 seconds\n",
            "The loss is 0.5791440486452348 and the accuracy is 0.8169866328616794 in Epoch 3\n",
            "4 epoch, 2000 batch, loss: 0.5201630808115005\n",
            "2000 batches take 210.0339879989624 seconds\n",
            "4 epoch, 4000 batch, loss: 0.5173222482651472\n",
            "2000 batches take 206.94077062606812 seconds\n",
            "4 epoch, 6000 batch, loss: 0.5140083432644605\n",
            "2000 batches take 206.2455370426178 seconds\n",
            "4 epoch, 8000 batch, loss: 0.5110495797246695\n",
            "2000 batches take 206.19395637512207 seconds\n",
            "4 epoch, 10000 batch, loss: 0.506557316377759\n",
            "2000 batches take 205.69175624847412 seconds\n",
            "4 epoch, 12000 batch, loss: 0.5033089226186276\n",
            "2000 batches take 207.01402616500854 seconds\n",
            "The loss is 0.5108629215231759 and the accuracy is 0.8367147468548599 in Epoch 4\n",
            "5 epoch, 2000 batch, loss: 0.45846539141237735\n",
            "2000 batches take 213.79771065711975 seconds\n",
            "5 epoch, 4000 batch, loss: 0.45467615638673303\n",
            "2000 batches take 208.8409457206726 seconds\n",
            "5 epoch, 6000 batch, loss: 0.45160875068604944\n",
            "2000 batches take 209.25942993164062 seconds\n",
            "5 epoch, 8000 batch, loss: 0.44982324297726156\n",
            "2000 batches take 207.86603474617004 seconds\n",
            "5 epoch, 10000 batch, loss: 0.4491954714208841\n",
            "2000 batches take 208.4881076812744 seconds\n",
            "5 epoch, 12000 batch, loss: 0.44756857807934286\n",
            "2000 batches take 207.69152665138245 seconds\n",
            "The loss is 0.45137915934482925 and the accuracy is 0.8553245050444019 in Epoch 5\n",
            "6 epoch, 2000 batch, loss: 0.44023525942862035\n",
            "2000 batches take 211.31625175476074 seconds\n",
            "6 epoch, 4000 batch, loss: 0.4398617060482502\n",
            "2000 batches take 205.838538646698 seconds\n",
            "6 epoch, 6000 batch, loss: 0.4390379272699356\n",
            "2000 batches take 203.89005041122437 seconds\n",
            "6 epoch, 8000 batch, loss: 0.43879815222322943\n",
            "2000 batches take 203.78708839416504 seconds\n",
            "6 epoch, 10000 batch, loss: 0.4378529518097639\n",
            "2000 batches take 204.1380078792572 seconds\n",
            "6 epoch, 12000 batch, loss: 0.43783171951770783\n",
            "2000 batches take 203.83397030830383 seconds\n",
            "The loss is 0.4389311420670945 and the accuracy is 0.8590195470576664 in Epoch 6\n",
            "7 epoch, 2000 batch, loss: 0.42995267754793165\n",
            "2000 batches take 207.74147176742554 seconds\n",
            "7 epoch, 4000 batch, loss: 0.4294028062969446\n",
            "2000 batches take 203.85149669647217 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed9gD33G1afy"
      },
      "source": [
        "test = np.load(\"/content/test.npy\", allow_pickle=True)\n",
        "total_test_datapoints = 0\n",
        "for i in test:\n",
        "  total_test_datapoints += i.shape[0]\n",
        "\n",
        "class MyTestDataset(Dataset):\n",
        "  def __init__(self, X):\n",
        "    super(MyTestDataset, self).__init__()\n",
        "\n",
        "    self.X = []\n",
        "    self.map = [0] * total_test_datapoints\n",
        "    self.size = 0\n",
        "    current_lower = 0\n",
        "    for index, utterance in np.ndenumerate(X):\n",
        "      size = utterance.shape[0]\n",
        "      self.size += size\n",
        "      padded_utterance = np.pad(utterance,((CONTEXT_SIZE,), (0,)), 'constant')\n",
        "      self.X.append(padded_utterance)\n",
        "      self.map[current_lower:current_lower+size] = [(index[0], k+CONTEXT_SIZE) for k in range(size)]\n",
        "      current_lower += size\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    utter_idx, frame_idx = self.map[index]\n",
        "    utter = self.X[utter_idx]       \n",
        "    X = torch.from_numpy(utter[frame_idx-CONTEXT_SIZE:frame_idx+CONTEXT_SIZE+1].flatten())\n",
        "    X = X.type(torch.FloatTensor)\n",
        "    return X\n",
        "\n",
        "\n",
        "test_dataset = MyTestDataset(test)\n",
        "del test\n",
        "test_loader_args = dict(shuffle=False, batch_size=256, num_workers=0, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, **test_loader_args)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAX7TkdmMtYr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6ccd295-1952-47ed-9344-25414c3a14b0"
      },
      "source": [
        "model.eval()\n",
        "pred = []\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    data = data.to(device)\n",
        "    outputs = model(data)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    pred += predicted.data.cpu().tolist()\n",
        "    del predicted\n",
        "    del outputs\n",
        "    # torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Done prediction!\")\n",
        "df = pd.DataFrame(pred, columns=['label'])\n",
        "df.to_csv(\"/content/submission.csv\", index_label=\"id\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done prediction!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}